{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO #libreria de ultralyltics\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CODIGO PARA YOLOV8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.105 🚀 Python-3.7.9 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12039MiB)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=coco128.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/ia1/.pyenv/runs/detect/train20\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.head.Detect           [80, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25902640 parameters, 25902624 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/ia1/.pyenv/runs/detect/train20', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ia1/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ia1/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "Plotting labels to /home/ia1/.pyenv/runs/detect/train20/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/ia1/.pyenv/runs/detect/train20\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3      6.96G     0.9925      0.948      1.143        218        640: 100%|██████████| 8/8 [00:05<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]\n",
      "                   all        128        929      0.731      0.719      0.785      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3      7.16G     0.9473      0.853      1.169        205        640: 100%|██████████| 8/8 [00:03<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.07it/s]\n",
      "                   all        128        929      0.771      0.739      0.807       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3       7.2G     0.9615     0.8465      1.135        161        640: 100%|██████████| 8/8 [00:03<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:05<00:00,  1.33s/it]\n",
      "                   all        128        929      0.819      0.725      0.819      0.647\n",
      "\n",
      "3 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from /home/ia1/.pyenv/runs/detect/train20/weights/last.pt, 52.1MB\n",
      "Optimizer stripped from /home/ia1/.pyenv/runs/detect/train20/weights/best.pt, 52.1MB\n",
      "\n",
      "Validating /home/ia1/.pyenv/runs/detect/train20/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.105 🚀 Python-3.7.9 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12039MiB)\n",
      "Model summary (fused): 218 layers, 25886080 parameters, 0 gradients, 79.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:05<00:00,  1.28s/it]\n",
      "                   all        128        929      0.822      0.725      0.819      0.647\n",
      "                person        128        254      0.937       0.72      0.865      0.664\n",
      "               bicycle        128          6          1      0.462      0.707      0.527\n",
      "                   car        128         46      0.862      0.272       0.58      0.323\n",
      "            motorcycle        128          5       0.79          1      0.962      0.848\n",
      "              airplane        128          6      0.962          1      0.995      0.905\n",
      "                   bus        128          7      0.827      0.714      0.885       0.76\n",
      "                 train        128          3      0.862          1      0.995      0.995\n",
      "                 truck        128         12      0.851      0.478      0.667      0.393\n",
      "                  boat        128          6      0.863        0.5      0.717      0.548\n",
      "         traffic light        128         14      0.759      0.226      0.456      0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "             stop sign        128          2      0.825          1      0.995      0.895\n",
      "                 bench        128          9      0.995      0.778      0.863      0.562\n",
      "                  bird        128         16      0.994          1      0.995      0.697\n",
      "                   cat        128          4      0.865          1      0.995      0.915\n",
      "                   dog        128          9      0.897          1      0.995      0.862\n",
      "                 horse        128          2      0.807          1      0.995      0.699\n",
      "              elephant        128         17      0.976      0.941      0.947      0.851\n",
      "                  bear        128          1      0.709          1      0.995      0.895\n",
      "                 zebra        128          4      0.888          1      0.995      0.949\n",
      "               giraffe        128          9      0.896          1      0.995      0.788\n",
      "              backpack        128          6      0.732      0.667      0.727      0.532\n",
      "              umbrella        128         18      0.801      0.894      0.947      0.683\n",
      "               handbag        128         19          1       0.26      0.544      0.416\n",
      "                   tie        128          7      0.968      0.857      0.859      0.663\n",
      "              suitcase        128          4      0.959          1      0.995      0.644\n",
      "               frisbee        128          5      0.761        0.8      0.807      0.778\n",
      "                  skis        128          1      0.743          1      0.995      0.995\n",
      "             snowboard        128          7      0.846       0.79       0.88      0.721\n",
      "           sports ball        128          6      0.799      0.662      0.663      0.426\n",
      "                  kite        128         10      0.781        0.4       0.57      0.216\n",
      "          baseball bat        128          4       0.29       0.25      0.412       0.27\n",
      "        baseball glove        128          7      0.782      0.429      0.459      0.301\n",
      "            skateboard        128          5          1      0.586      0.805      0.555\n",
      "         tennis racket        128          7      0.925      0.714       0.72      0.427\n",
      "                bottle        128         18      0.712       0.55      0.682      0.472\n",
      "            wine glass        128         16          1      0.499      0.726      0.505\n",
      "                   cup        128         36      0.965      0.771      0.906      0.579\n",
      "                  fork        128          6      0.715      0.429      0.625      0.409\n",
      "                 knife        128         16      0.911      0.644      0.839      0.625\n",
      "                 spoon        128         22      0.871      0.773      0.772      0.577\n",
      "                  bowl        128         28      0.954      0.746      0.824      0.709\n",
      "                banana        128          1      0.682          1      0.995      0.995\n",
      "              sandwich        128          2      0.415        0.5      0.745      0.745\n",
      "                orange        128          4      0.955          1      0.995      0.766\n",
      "              broccoli        128         11      0.746      0.182      0.379      0.305\n",
      "                carrot        128         24       0.67      0.763      0.784      0.577\n",
      "               hot dog        128          2      0.623          1      0.995      0.995\n",
      "                 pizza        128          5      0.902          1      0.995      0.871\n",
      "                 donut        128         14      0.736          1      0.972      0.899\n",
      "                  cake        128          4      0.844          1      0.995      0.902\n",
      "                 chair        128         35      0.724      0.673      0.733      0.506\n",
      "                 couch        128          6          1      0.657      0.955      0.766\n",
      "          potted plant        128         14      0.844      0.775      0.901       0.65\n",
      "                   bed        128          3      0.957          1      0.995      0.848\n",
      "          dining table        128         13      0.813      0.692      0.741      0.603\n",
      "                toilet        128          2      0.823          1      0.995      0.946\n",
      "                    tv        128          2      0.791          1      0.995      0.946\n",
      "                laptop        128          3      0.581      0.667      0.617      0.578\n",
      "                 mouse        128          2          1          0      0.497      0.175\n",
      "                remote        128          8          1      0.603      0.721      0.642\n",
      "            cell phone        128          8      0.753        0.5      0.622      0.386\n",
      "             microwave        128          3      0.656          1      0.995      0.852\n",
      "                  oven        128          5      0.509        0.4      0.388      0.295\n",
      "                  sink        128          6      0.611      0.527      0.646      0.389\n",
      "          refrigerator        128          5      0.696          1      0.962      0.769\n",
      "                  book        128         29       0.71      0.345      0.469      0.295\n",
      "                 clock        128          9      0.801      0.889      0.943      0.803\n",
      "                  vase        128          2      0.615          1      0.995      0.921\n",
      "              scissors        128          1          1          0      0.995      0.232\n",
      "            teddy bear        128         21       0.81      0.619      0.801      0.613\n",
      "            toothbrush        128          5          1      0.873      0.995      0.829\n",
      "Speed: 1.0ms preprocess, 13.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/ia1/.pyenv/runs/detect/train20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.105 🚀 Python-3.7.9 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12039MiB)\n",
      "Model summary (fused): 218 layers, 25886080 parameters, 0 gradients, 79.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ia1/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.60it/s]\n",
      "                   all        128        929      0.808      0.734       0.82      0.652\n",
      "                person        128        254      0.925       0.73      0.868      0.669\n",
      "               bicycle        128          6          1      0.471       0.71      0.531\n",
      "                   car        128         46      0.865      0.278      0.563      0.326\n",
      "            motorcycle        128          5      0.785          1      0.962      0.848\n",
      "              airplane        128          6       0.94          1      0.995      0.905\n",
      "                   bus        128          7      0.799      0.714       0.89      0.773\n",
      "                 train        128          3      0.855          1      0.995      0.995\n",
      "                 truck        128         12      0.845      0.457       0.65      0.392\n",
      "                  boat        128          6      0.846        0.5      0.727       0.57\n",
      "         traffic light        128         14      0.768       0.24      0.457      0.256\n",
      "             stop sign        128          2      0.814          1      0.995      0.895\n",
      "                 bench        128          9      0.896      0.778      0.863      0.567\n",
      "                  bird        128         16      0.984          1      0.995      0.707\n",
      "                   cat        128          4      0.858          1      0.995      0.915\n",
      "                   dog        128          9      0.891          1      0.995      0.907\n",
      "                 horse        128          2      0.799          1      0.995      0.699\n",
      "              elephant        128         17      0.963      0.941      0.947      0.851\n",
      "                  bear        128          1      0.697          1      0.995      0.895\n",
      "                 zebra        128          4      0.883          1      0.995      0.973\n",
      "               giraffe        128          9      0.943          1      0.995      0.765\n",
      "              backpack        128          6      0.652      0.667      0.727      0.492\n",
      "              umbrella        128         18      0.808      0.936      0.947      0.683\n",
      "               handbag        128         19          1      0.277      0.564      0.425\n",
      "                   tie        128          7      0.928      0.857      0.859      0.679\n",
      "              suitcase        128          4      0.908          1      0.995      0.661\n",
      "               frisbee        128          5      0.756        0.8      0.808      0.778\n",
      "                  skis        128          1      0.726          1      0.995      0.995\n",
      "             snowboard        128          7      0.864      0.857      0.907      0.711\n",
      "           sports ball        128          6      0.783      0.667      0.662      0.414\n",
      "                  kite        128         10       0.76        0.4      0.568      0.213\n",
      "          baseball bat        128          4      0.282       0.25      0.258       0.19\n",
      "        baseball glove        128          7      0.706      0.429      0.459      0.308\n",
      "            skateboard        128          5          1      0.583      0.878      0.611\n",
      "         tennis racket        128          7      0.912      0.714       0.72      0.431\n",
      "                bottle        128         18      0.742      0.641      0.701      0.485\n",
      "            wine glass        128         16      0.839      0.438      0.757      0.525\n",
      "                   cup        128         36      0.908       0.75      0.898       0.58\n",
      "                  fork        128          6      0.717      0.433      0.618       0.44\n",
      "                 knife        128         16      0.915      0.676      0.825       0.61\n",
      "                 spoon        128         22      0.849      0.773      0.759      0.572\n",
      "                  bowl        128         28      0.875      0.714      0.824      0.713\n",
      "                banana        128          1      0.656          1      0.995      0.995\n",
      "              sandwich        128          2      0.602      0.807      0.828      0.828\n",
      "                orange        128          4      0.912          1      0.995      0.766\n",
      "              broccoli        128         11      0.732      0.182      0.366       0.29\n",
      "                carrot        128         24      0.677      0.786      0.786      0.583\n",
      "               hot dog        128          2      0.595          1      0.995      0.995\n",
      "                 pizza        128          5      0.882          1      0.995      0.867\n",
      "                 donut        128         14      0.733          1      0.972       0.89\n",
      "                  cake        128          4      0.836          1      0.995      0.902\n",
      "                 chair        128         35      0.664      0.686      0.733      0.504\n",
      "                 couch        128          6          1      0.666      0.955      0.766\n",
      "          potted plant        128         14      0.846      0.783      0.901      0.646\n",
      "                   bed        128          3      0.932          1      0.995      0.863\n",
      "          dining table        128         13      0.873      0.769      0.766      0.614\n",
      "                toilet        128          2       0.81          1      0.995      0.946\n",
      "                    tv        128          2      0.781          1      0.995      0.946\n",
      "                laptop        128          3      0.572      0.667      0.654      0.605\n",
      "                 mouse        128          2          1          0      0.497      0.207\n",
      "                remote        128          8          1      0.608      0.713      0.643\n",
      "            cell phone        128          8      0.678        0.5      0.626       0.39\n",
      "             microwave        128          3      0.633          1      0.995      0.909\n",
      "                  oven        128          5      0.499        0.4      0.401      0.302\n",
      "                  sink        128          6      0.622      0.556      0.596      0.377\n",
      "          refrigerator        128          5      0.688          1      0.962      0.769\n",
      "                  book        128         29      0.712      0.341      0.481      0.283\n",
      "                 clock        128          9      0.774      0.889      0.943      0.803\n",
      "                  vase        128          2      0.601          1      0.995      0.995\n",
      "              scissors        128          1          1          0      0.995      0.225\n",
      "            teddy bear        128         21      0.762      0.619      0.794      0.607\n",
      "            toothbrush        128          5          1      0.915      0.995      0.846\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/ia1/.pyenv/runs/detect/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()  # evaluate model performance on the validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up unused tensors\n",
    "tensor = None\n",
    "\n",
    "# Empty the GPU cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 18 cows, 15.1ms\n",
      "Speed: 17.6ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results = model('/home/ia1/Downloads/ganado.jpg')  # predict on an image\n",
    "\n",
    "#results = model.predict(source=\"0\")\n",
    "#results = model.predict(source=\"/home/ia1/Downloads/\", show=True) # Display preds. Accepts all YOLO predict arguments\n",
    "\n",
    "# from PIL\n",
    "#im1 = Image.open(\"/home/ia1/Downloads/ganado.jpg\")\n",
    "#results = model.predict(source=im1, save=True)  # save plotted images\n",
    "img= cv2.imread(\"/home/ia1/Downloads/ganado.jpg\")\n",
    "#img= cv2.imread('/home/ia1/cv/Proyectos/Pereda/videos dron/videos campo/DJI_0009.JPG')\n",
    "res = model(img)\n",
    "boxes = res[0].boxes\n",
    "res_plotted = res[0].plot(boxes=boxes)\n",
    "cv2.imshow(\"result\", res_plotted)\n",
    "#cv2.imwrite('ganados23.png',img)\n",
    "cv2.imwrite('ganados22.png',res_plotted)\n",
    "\n",
    "#success = model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CODIGO DE YOLOV5 (anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= torch.hub.load('ultralytics/yolov5', 'yolov5l6')# modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes= [19]\n",
    "model.conf= 0.1\n",
    "\n",
    "num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread('/home/ia1/Downloads/ganado.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread('/home/ia1/cv/Proyectos/contar objetos/cows.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread('/home/ia1/cv/Proyectos/Pereda/videos dron/videos campo/DJI_0009.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COSINE_DISTANCE = 0.2 # umbral de objeto coincidente\n",
    "NN_BUDGET = 100\n",
    "#\n",
    "'''\n",
    "métrica de instancia de clase de rastreador = NearestNeighborDistanceMetric (\n",
    "\"coseno\", MAX_COSINE_DISTANCE, NN_BUDGET\n",
    ")'''\n",
    "rastreador = rastreador (\n",
    "métrica,\n",
    "max_iou_distance=0.7,\n",
    "max_age=70,\n",
    "n_init=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update tracker\n",
    "tracker.predict()\n",
    "tracker.update(detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_ganado(img):\n",
    "    global num\n",
    "    x= img.shape[1]\n",
    "    y= img.shape[0]\n",
    "    result= model(img)\n",
    "    tensor= result.xyxyn[0]\n",
    "    for i in range(tensor.size()[0]):\n",
    "        box= tensor[i][0:4]\n",
    "        num= str(i+1)\n",
    "        xmin= int(tensor[i][0]*x)\n",
    "        ymin= int(tensor[i][1]*y)\n",
    "        xmax= int(tensor[i][2]*x)\n",
    "        ymax= int(tensor[i][3]*y)\n",
    "        cv2.rectangle(img, (xmin,ymin), (xmax,ymax),(0, 255, 0),3)\n",
    "        cv2.putText(img,num, ((int)(xmax),(int)(ymax)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,0,0),2)\n",
    "    #cv2.putText(img,num, (int(20),int(20)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,0,0),2)\n",
    "    cv2.imwrite('ganado.png',img)\n",
    "    img_pil= Image.fromarray(img)\n",
    "    return img_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contar_ganado(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contar_ganado(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap= cv2.VideoCapture('/home/ia1/Downloads/ganado.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap= cv2.VideoCapture('/home/ia1/cv/Proyectos/Pereda/videos dron/videos campo/DJI_0007.MP4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = int(cap.get(3))  # float\n",
    "h = int(cap.get(4)) # float\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('ganado2.avi', fourcc, 20.0, (w,h))\n",
    "while(True):\n",
    "    ret, frame= cap.read()\n",
    "    result= model(frame)\n",
    "    result.render()\n",
    "    out.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = cap.get(3)  # float\n",
    "h = cap.get(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
